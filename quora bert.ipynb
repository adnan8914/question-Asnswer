{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0b96ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\adnan\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.24.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8214cf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\adnan\\anaconda3\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\adnan\\anaconda3\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\adnan\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\adnan\\anaconda3\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\adnan\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\adnan\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\adnan\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers[torch]) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers[torch]) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers[torch]) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers[torch]) (0.33.0)\n",
      "Requirement already satisfied: torch in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers[torch]) (2.2.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: sympy in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from torch->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: click in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch] tokenizers datasets evaluate rouge_score sentencepiece huggingface_hub --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dea0163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\adnan\\anaconda3\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from evaluate) (2.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: dill in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from evaluate) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from evaluate) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from evaluate) (0.24.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3c2c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adnan\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61cfad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"toughdata/quora-question-answer-dataset\")\n",
    "ds = ds['train'].train_test_split(test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8d877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48cb7f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 33841\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 22561\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93245e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': ['What would happen if Led Zeppelin went on tour and replaced Robert Plant with Eddie Vedder?',\n",
       "  'As a stay-at-home parent, how much help do you get from your partner when running the home and looking after the kids?',\n",
       "  'How does a wave function collapse in quantum mechanics/physics?',\n",
       "  'What do teenagers wish adults understood?',\n",
       "  \"Is the claim that Palestinian ethnicity doesn't exist, and is actually a mix of different Arab nationalities (Jordanian, etc) just a false conspiracy theory?\"],\n",
       " 'answer': ['A2a\\n It would be an interesting but failed experiment. I don’t see Ed’s vocals as similar to Plant in any way.\\n Plus Ed has clearly aligned himself with the Who as the inspirational band from that era for him.\\n Makes no real sense to do this.\\n',\n",
       "  \"It depends! My husband and I have 3 kids (6, 3 and 6 months). I'll say this first, he doesn't wash dishes, do bath time with the kids, nor does he do laundry.\\n Somedays he will clean up after supper, an odd time he will unload the dishwasher. The house doesn't get too dirty since I'm home all day but 99% of the cleaning gets done by me or by my helpful 6 year old. The cleaning gets done during the day, not in the evening.\\n Our 6 month old is our trouble baby (our other two were amazingly well behaved and happy babies), so she's usually having a fit or being disruptive in which case my husband will get pajamas on our 3 year old and get that bedroom “bedtime” ready, or he will help them out of the bath or wipe a bum (if the baby is in a foul mood). If the baby is behaving, I do it all.\\n We each get a sleep in day on the weekend, which (usually) will be the only time my husband prepares breakfast for the kids or changes a diaper. (He gets up at 6am and is at work by 7am, he's usually back at 6pm and the kids go to bed at 8pm).\\n He gets silly with the kids often, goes outside with them, listens to their stories etc.\\n He can keep them occupied or tuck them into bed without me if needed.\\n So if I NEED help, he usually will (with the kids not so much with the chores). But for the most part, I don't need the help.\\n The only thing I wish I got was more personal time (not having to rush a bath or shower because he can't alway handle the baby or to give me an hour 3 times a week to work out). But when he usually only has 3 hours at home before he falls asleep, I can't be too upset over it.\\n But I do get a bit jaded when he falls asleep on the couch, showered and in pjs while I'm trying to get the baby down (with me usually not showered or in pjs yet and with bottles that have to ben cleaned before bed). I usually end up going to bed 2 hours after he falls asleep (to which I wake him up and we go to bed together, but would be handy if he would wash bottles before he falls asleep).\\n\",\n",
       "  'It doesn\\'t. Wavefunction collapse is not a physical process. It is a mental model, arguably a flawed one, of the most problematic aspect of the quantum theory. (NB: What follows is influenced in part by my personal views on the topic and while the facts that I present are not controversial, my views do not necessarily reflect the entirety of the physics community.)\\n Here is the problem. The quantum theory describes the state of a physical system as a superposition (weighted sum) of so-called eigenstates (the German prefix eigen- meaning proper or something similar). An act of measurement: that is, interaction between the quantum system and a classical measuring instrument, confines the quantum system to a specific eigenstate. If the instrument is removed, the quantum system evolves into a superposition of many (possibly infinitely many) eigenstates. This evolution is governed by some variant of the Schrödinger equation, which depicts a \"unitary evolution\" of the quantum system\\'s wavefunction.\\n But when another measurement takes place, it selectively picks one eigenstate out of many. The wavefunction tells us the probabilities associated with each eigenstate but does not determine which eigenstate will prevail. This instantaneous, retroactive (!), \"non-unitary\" evolution of the wavefunction from a superposition of eigenstates to a specific eigenstate is what is called wavefunction collapse. This collapse is not governed by Schrödinger\\'s equation or indeed any reasonable equation. It is essentially magic: one system (the quantum system before the measurement, with the measuring apparatus absent from the description) is magically and retroactively replaced by another (the quantum system confined by the measurement, with the apparatus part of the system\\'s description.)\\n An alternative view would be to assume that the quantum system has \"known\" about the presence of the measuring apparatus all along, even before it interacted with it. This nonlocality, somewhat surprisingly, does not bring about any violations of causality: no present-day observable is altered by how the measuring apparatus is arranged in the future. Nonetheless, this nonlocality is widely treated with skepticism. Instead, there are alternative depictions proposed, including Bohm\\'s \"pilot waves\", Everett’s “many worlds” or the Copenhagen interpretation\\'s \"wavefunction collapse\". Ironically, none of these interpretations actually get rid of the fundamental nonlocality of the theory (indeed, according to Bell\\'s theorem, it really isn\\'t possible), so they really are merely attempts to make the description more palatable to our prejudices.\\n What the equations do say, at face value, is that a future interaction with the measuring apparatus influences the present-day (but unobservable) properties of the wavefunction, allowing the quantum system to evolve from one observed eigenstate to another observed eigenstate through unitary evolution and without any deus ex machina-like wavefunction collapse.\\nI thank my generous supporters on [LINKED_TEXT: Patreon] [URL: https://www.patreon.com/vttoth]. If you like my answers, please consider joining them.\\n',\n",
       "  'God I have so many but here’s a new one so you’re not reading the same answer.\\n If you look at our texts, we’re going to delete them anyways. You’d be surprised at how quick we are.\\n Amen 🙏\\n',\n",
       "  'While there is Jordan as a national homeland of the Jordanian people, they are not any different ethnically then the Arabs who call themselves Palestinians, Syrians, or Saudi’s.\\n The Question of the Palestinians, I guess the best way to deal with this is to look at what their own people said concerning themselves:\\n> -Professor Azmi Bishara(Arabic: عزمي بشارة)– a “Palestinian Arab” “There is no “Palestinian nation”, The word “Palestine” itself is a colonial invention used by the Romans in order to erase the Jewish identity of Judea and Israel! [ http://www.palwatch.org/main.aspx?fi=495 ]\\n Walid Shoebatt, who was a former PLO terrorist, acknowledged the lie he had been fighting for when he asked, “Why is it that on June 4th, 1967, I went to bed as a Jordanian and woke up as a Palestinian? We considered ourselves Jordanian ...\\n']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][slice(None, 5, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ca362fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': [\"Is attending your youngest daughter's wedding in direct violation of a protective/restraining order a bad idea even if you have a well-rehearsed apology speech at-the-ready?\",\n",
       "  'What is your favorite sci-fi book series, and why?',\n",
       "  'Was Iran/Persia powerful before? Was it full of barbarians as mentioned in the movie “300”? If it was, then did Persians raise the three empires of Achamedians, Safavid, and Sasanian?',\n",
       "  'What is the best Bollywood song for caller tune?',\n",
       "  'Why do some people like to stay in an abusive relationship?'],\n",
       " 'answer': ['The fact that someone would even consider doing this is a great example of why the restraining order was put in place.\\n This is their day. Not yours. You do not have a single right to interrupt it in any way, shape or form.\\n I can only presume you put your needs over and above your child’s consistently in the past.\\n You appear to have learnt nothing.\\n She sees you as a sperm donor not a father because you have clearly never earned the honour of being a true dad.\\n',\n",
       "  'There are many acclaimed science fiction novels that have captivated readers over the years. Here are some of the best science fiction novels that have made a significant impact:\\n\"Dune\" by Frank Herbert: This epic tale is set in a distant future and explores political intrigue, religion, and environmental themes in a richly imagined universe.\"1984\" by George Orwell: A dystopian classic that depicts a totalitarian society and explores themes of surveillance, government control, and individual freedom.\"Foundation\" by Isaac Asimov: This novel introduces the concept of psychohistory and follows the story of Hari Seldon as he predicts the fall of the Galactic Empire.\"Neuromancer\" by William Gibson: A groundbreaking cyberpunk novel that delves into artificial intelligence, virtual reality, and the implications of technology on society.\"Ender\\'s Game\" by Orson Scott Card: Set in a future where humanity faces an alien threat, this novel follows a gifted child, Ender Wiggin, as he trains in a battle school to save humanity.\"The Left Hand of Darkness\" by Ursula K. Le Guin: This thought-provoking novel explores themes of gender and sexuality in a society where individuals are androgynous most of the time.\"Brave New World\" by Aldous Huxley: Another classic dystopian novel that presents a future society built on technological advancements, genetic engineering, and social control.\"Snow Crash\" by Neal Stephenson: This cyberpunk novel combines virtual reality, ancient Sumerian mythology, and fast-paced action in a near-future setting.\"Hyperion\" by Dan Simmons: A multi-award-winning novel that weaves together multiple narratives, featuring a group of pilgrims on a journey through a universe ruled by powerful entities known as the Shrike.\"The Hitchhiker\\'s Guide to the Galaxy\" by Douglas Adams: A comedic and satirical science fiction series that follows the misadventures of Arthur Dent as he travels across the universe.\\nThese novels offer a range of themes, styles, and subgenres within science fiction. They have had a lasting impact on the genre and have garnered critical acclaim and a dedicated readership. Exploring these works can provide a captivating journey into imaginative worlds and thought-provoking ideas.\\n',\n",
       "  'The Term Barbarians is equal with AnIranian for Persian Empires Political view ,\\n but i still do not believing that Greeks called Persian BARBARIANS when they invented the word imperialist for the first time in history for calling Persian Empire !\\n so how Imperialist could be Barbarians ?\\n',\n",
       "  'Main phir bhi tumko chahunga.\\n',\n",
       "  \"Love is a reason. Lily thinks of it the right way, “Just because someone hurts you doesn't mean you can simply stop loving them. It's not the person's actions that hurt the most. It's the love.”\\n Lily, the protagonist of Colleen Hoover’s It Ends With Us.\\nRyle loved Lily. It showed in his altering his major life rules for her, rejecting his highest career goal and supporting hers instead— all, however, did get squandered because his aggression dominated his affection, at times.\\n Repeating his violent actions, Ryle was apologetic— a common reason why people do not leave. They apologize, and are granted chance upon chance, hoping for a change.\\n He was genuinely sorry for having mistreated her. He never wanted to be the reason for her affliction. He never wanted to lose her. He had promised to never repeat it the first time he ‘accidentally’ hit her. Ryle loved Lily. But love doesn't allow violence, with no excuse whatever.\\nRyle knew he was problematic. It ached him knowing he caused her aches (I almost rooted for him, ngl). He lived through his childhood trauma, and thus, struggled with PTSD. But your sufferings, in no way, excuse you to make others suffer.\\nLily, at last, sought refuge in Atlas, her first love. The perfect guy, who isn't commonly found outside these tales. Another reason why people don't leave. There isn't everyone's true love waiting for them. They compromise, constantly hoping that their love will paint all red flags, green.\\n I doubt if Lily would've been bold enough to ask Ryle for divorce if Atlas hadn't returned to her life.\\nAnd the last reason— their child. Children are usually the reason why parents don't separate, no matter how toxic one of them turns out. They think it to be the best to let their child live with both parents together.\\nBut since Lily was such a child, she didn't want her daughter to do the same— view her father through a negative lens. She knew that the moments of her father being cruel are bound to leave an impact on her mind. She saved Ryle from being a villain in his daughter's eyes. They shared the custody of their child, but not their lives.\\nThere exist very many reasons to stay, but if physical or mental stability is threatened, it isn't worth taking the risk.\\n It's worth rather taking excruciating pain to end it at the moment.\\n“Cycles continue because they are excruciating to break.”\\n ~Colleen Hoover, It Ends With Us.\\n\"]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][slice(None, 5, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d63b26fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the text\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', '', text).strip()\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "073c2e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Stop Words\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e762329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4ba24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(tokens):\n",
    "    return [stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdfcda85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "600b9311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the cleaning func\n",
    "#def preprocess_func(temp):\n",
    "#    temp['processed_question'] = remove_stopwords(clean_text(temp['question']))\n",
    "#   temp['processed_question'] = remove_stopwords(clean_text(temp['answer']))\n",
    "#   return temp\n",
    "#processed_ds = ds.map(preprocess_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2e648df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_func(example):\n",
    "    # Clean the text\n",
    "    cleaned_question = clean_text(example['question'])\n",
    "    cleaned_answer = clean_text(example['answer'])\n",
    "    \n",
    "    # Remove stop words\n",
    "    cleaned_question = remove_stopwords(cleaned_question)\n",
    "    cleaned_answer = remove_stopwords(cleaned_answer)\n",
    "\n",
    "    # Tokenize\n",
    "    question_tokens = tokenize(cleaned_question)\n",
    "    answer_tokens = tokenize(cleaned_answer)\n",
    "    \n",
    "    # Apply stemming or lemmatization (uncomment the desired method)\n",
    "     #question_tokens = stem(question_tokens)\n",
    "    # answer_tokens = stem(answer_tokens)\n",
    "    \n",
    "    question_tokens = lemmatize(question_tokens)\n",
    "    answer_tokens = lemmatize(answer_tokens)\n",
    "\n",
    "    # Join tokens back into strings\n",
    "    example['processed_question'] = ' '.join(question_tokens)\n",
    "    example['processed_answer'] = ' '.join(answer_tokens)\n",
    "    \n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf8e3a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad1e331d999457c882a6e3ba64f1ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the cleaned train dataset:\n",
      "                                  processed_question  \\\n",
      "0  whatwouldhappenifledzeppelinwentontourandrepla...   \n",
      "1  asastayathomeparenthowmuchhelpdoyougetfromyour...   \n",
      "2  howdoesawavefunctioncollapseinquantummechanics...   \n",
      "3                whatdoteenagerswishadultsunderstood   \n",
      "4  istheclaimthatpalestinianethnicitydoesntexista...   \n",
      "\n",
      "                                    processed_answer  \n",
      "0  aaitwouldbeaninterestingbutfailedexperimentido...  \n",
      "1  itdependsmyhusbandandihavekidsandmonthsillsayt...  \n",
      "2  itdoesntwavefunctioncollapseisnotaphysicalproc...  \n",
      "3  godihavesomanybutheresanewonesoyourenotreading...  \n",
      "4  whilethereisjordanasanationalhomelandofthejord...  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f65c10abc5452eb8ce61112ffa032e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22561 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of the cleaned test dataset:\n",
      "                                  processed_question  \\\n",
      "0  isattendingyouryoungestdaughtersweddingindirec...   \n",
      "1            whatisyourfavoritescifibookseriesandwhy   \n",
      "2  wasiranpersiapowerfulbeforewasitfullofbarbaria...   \n",
      "3            whatisthebestbollywoodsongforcallertune   \n",
      "4   whydosomepeopleliketostayinanabusiverelationship   \n",
      "\n",
      "                                    processed_answer  \n",
      "0  thefactthatsomeonewouldevenconsiderdoingthisis...  \n",
      "1  therearemanyacclaimedsciencefictionnovelsthath...  \n",
      "2  thetermbarbariansisequalwithaniranianforpersia...  \n",
      "3                           mainphirbhitumkochahunga  \n",
      "4  loveisareasonlilythinksofittherightwayjustbeca...  \n"
     ]
    }
   ],
   "source": [
    "for split_name, split_data in ds.items():\n",
    "    processed_ds = split_data.map(preprocess_func)\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    cleaned_df = processed_ds.to_pandas()\n",
    "    \n",
    "    # Drop original columns\n",
    "    cleaned_df = cleaned_df.drop(columns=['question', 'answer'])\n",
    "    \n",
    "    # Save the cleaned dataset to CSV\n",
    "    cleaned_df.to_csv(f'cleaned_{split_name}_dataset.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nFirst 5 rows of the cleaned {split_name} dataset:\")\n",
    "    print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99102db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\adnan\\anaconda3\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\adnan\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: torch in c:\\users\\adnan\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8baa5d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\adnan\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (0.24.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adnan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1007e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, EncoderDecoderModel, Trainer, TrainingArguments\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebdcda13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the processed data \n",
    "train_df = pd.read_csv('C:/Users/Adnan/cleaned_train_dataset.csv')\n",
    "test_df = pd.read_csv('C:/Users/Adnan/cleaned_test_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "834aade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for BERT2BERT\n",
    "train_df['input_text'] = train_df['processed_question']\n",
    "train_df['target_text'] = train_df['processed_answer']\n",
    "test_df['input_text'] = test_df['processed_question']\n",
    "test_df['target_text'] = test_df['processed_answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "495ebb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into smaller subsets\n",
    "num_splits = 4  # Define the number of splits\n",
    "train_subsets = np.array_split(train_df[['input_text', 'target_text']], num_splits)\n",
    "test_subsets = np.array_split(test_df[['input_text', 'target_text']], num_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fae9b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e625ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to tokenize the datasets\n",
    "def tokenize_function(examples):\n",
    "    input_texts = [str(text) for text in examples['input_text']]\n",
    "    target_texts = [str(text) for text in examples['target_text']]\n",
    "    \n",
    "    model_inputs = tokenizer(input_texts, max_length=512, truncation=True, padding='max_length')\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(target_texts, max_length=512, truncation=True, padding='max_length')\n",
    "    \n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f29dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea93260fc2645b78c9b3d06f3702ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8461 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adnan\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:4144: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc433dec306442d8d0c9accf91b95eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5641 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8d47120d3a46c0ae0e47d4627c868c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb30e02ae364efdaa0af8a7e2c0ea4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342c94f1d3f94bf48b01af2e20ebe8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3e83cc65f24b4c95e25e97db0ba174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f240e4f376e1478e842e0ce30488a65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f466a6607c4432bb9364aa09b59fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adnan\\anaconda3\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:623: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "C:\\Users\\Adnan\\anaconda3\\Lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='2115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/2115 01:25 < 50:10:05, 0.01 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train multiple models in parallel on the subsets\n",
    "models = []\n",
    "\n",
    "for i, (train_subset, test_subset) in enumerate(zip(train_subsets, test_subsets)):\n",
    "    train_dataset = Dataset.from_pandas(train_subset.reset_index(drop=True))\n",
    "    test_dataset = Dataset.from_pandas(test_subset.reset_index(drop=True))\n",
    "    \n",
    "    train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "    test_tokenized = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained('bert-base-uncased', 'bert-base-uncased')\n",
    "\n",
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \n",
    "    output_dir=f'./results_{i}',\n",
    "    num_train_epochs=1,  # Reduced epochs for quicker training\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=f'./logs_{i}',\n",
    "    logging_steps=10,\n",
    "    fp16=torch.cuda.is_available(),  # Enable fp16 only if GPU is available\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    dataloader_num_workers=4  # Use multiple workers for data loading\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Results for model {i}: {eval_results}\")\n",
    "\n",
    "model.save_pretrained(f'./bert2bert-chatbot-model_{i}')\n",
    "tokenizer.save_pretrained(f'./bert2bert-chatbot-model_{i}')\n",
    "models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(question, model, tokenizer):\n",
    "    input_text = question\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=512, pad_token_id=tokenizer.pad_token_id)\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a1ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with the first model\n",
    "best_model = models[0]\n",
    "best_tokenizer = tokenizer\n",
    "print(generate_response(\"What is the capital of France?\", best_model, best_tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
